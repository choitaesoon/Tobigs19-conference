{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6WGl6pxxLUR4k7rEC+Y3d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"37mbWzppe887"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UWGWB-XKQIM1"},"source":["#최종모델 구축"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4K1c9c1SQfyo"},"outputs":[],"source":["# 1. input text -> 요약모델을 통한 한문장 생성\n","# 2. 요약된 한문장을 3개의 유사도 문장 추출\n","# 3. threshhold(유사도가 0.5이상)와 긍/부정 모델에 따른 최종 라벨 판단\n","# 4. input text 문장이 거짓 label로 판단된 경우 올바른 참 label에 맞는 문장 추출"]},{"cell_type":"markdown","metadata":{"id":"SSJW4QaLmLNC"},"source":["### 필요한 패키지 설치"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29068,"status":"ok","timestamp":1688715112424,"user":{"displayName":"최태순","userId":"04818132344604401268"},"user_tz":-540},"id":"qdCGFMQ6T5SG","outputId":"5fea38ee-1aae-473f-f8a1-a28de5d64471"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n","Collecting datasets\n","  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.14 xxhash-3.2.0\n","Collecting sentence_transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.30.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n","Collecting sentencepiece (from sentence_transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n","Building wheels for collected packages: sentence_transformers\n","  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=a13fe34c97ca5203d6b9b1ca8094a6010f5625174f9a67e6f3427c1761c42cc3\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence_transformers\n","Installing collected packages: sentencepiece, sentence_transformers\n","Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n"]}],"source":["# 패키지 설치\n","!pip install transformers\n","!pip install datasets\n","!pip install sentence_transformers\n","\n","# 패키지 로드\n","import pandas as pd\n","import torch\n","from transformers import PreTrainedTokenizerFast, BartModel,BartForConditionalGeneration\n","import math\n","import re\n","import logging\n","from datetime import datetime\n","from torch.utils.data import DataLoader\n","from datasets import load_dataset\n","from sentence_transformers import SentenceTransformer, LoggingHandler, losses, models, util\n","from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","from sentence_transformers.readers import InputExample\n","from nltk.translate.bleu_score import corpus_bleu\n","from transformers import pipeline, AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0yMmTZUmY5N"},"outputs":[],"source":["input = '문재인 아들 비리의혹에 관련한 기사~~'"]},{"cell_type":"markdown","metadata":{"id":"EV4piYm9mQR9"},"source":["###1.요약모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOK-ogarQV14"},"outputs":[],"source":["#기사 본문 정규식\n","def text_preprocess(text):\n","    text = re.sub(\"(<span class='quot[0-9]'>|\\n\\r\\n|</span>|<br/>|<br />|([^0-9가-힣A-Za-z. ]))\",\"\",text)\n","    return text\n","\n","\n","# 요약모델 함수\n","def summarization(input):\n","  tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n","  model_sm = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n","\n","  content = text_preprocess(input)\n","  text = re.sub(' +', ' ', content)\n","  raw_input_ids = tokenizer.encode(text)\n","  input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n","\n","  if len(input_ids) > 1024:\n","    summary_text = '해당 기사 본문 내용이 너무 지나치게 길어서 요약에 실패했습니다. 좀더 적은 양의 본문 내용을 뽑아주세요'\n","  else:\n","    summary_ids = model_sm.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n","    summary_text = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n","  return summary_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195,"referenced_widgets":["ec2fa8e83ee3456d9dcbcd5129bd49ea","209f46dd0d8d4c32910f517efd162927","a156f2d50f104a198f5e0f89a4f89b0a","adb565d4bb1f4591be938353702e7558","0525e63596f540c09c282e9cda96c8e9","9eec432a8f0347b48dd8a424fd62efe4","b7fd911fd1eb4c6d9d2a2d2256221d25","d12cc5f0925144968b89b560435476a3","8e01190a3c6b4286be102e9489960afb","7546e0c40efb46afba62c8f9c6fba3e5","6c407ee6af714a08a861aa008c9e7f5f","082e197443d44210ab18d672cb01acf8","e9d89d33d4fd4456a8eda3782fcf740e","46fedabd44a24fe1a0a23bc37be132c9","b8c6b0afa972483d96bbd60fba514af5","a1525a2e1a404e6e98316d0fa903c3c0","2eff8d653bc9425cad868b44be8ce584","2919c05908b643b6aac2c068c30a88c0","9ec20e66d29047809fe60178870a4bef","db0630a51d0c4e2e924064427778122d","123fb84d8375480384ee8177de3030e9","88954d99c1df4f8e87ffa04109cfd98b","6ba2a4260e524873874dab9eff88d9a4","e8910e8e17414bb5bcbdb22bca756d5d","5fcc056db1d64cc790315e0baa76181f","ade6cedbadff45b78cff12ec2a9fa02b","3153b83d775748eeb2c52bef5e828adb","28c34395a4e54fa3a91ab8e847815312","ac225a795ec6494283a41bf7f2fc9e2f","459852c58e9c4f019b629017fbc382f2","667e8e52903a4a1f8d5fd378bb7a769d","7d7cbb3f7eb243b2af5b1ce43972838d","9e7b83053b2c4feb9383301c3939591e","d6165df4faa4463f933c785704878368","e30df69893a64713a5703b3a1d252653","f86923050bfd40a9959e8adeb5dcc095","25b300e746bf4b4eadd1eed2bc9b6a28","a5449edf14664280ab456396152fdc0f","e5377b3ff7044846aefd532eec09d54f","999a27d5c9f246048856d0fd948a9eef","14730f299fdb40a8a46e17d454ca4f61","c8bd45ff60654b21b52766f44cb702f5","97a9d2b64684466fb6bdd839ba287a1a","420c87a1528a4358b3407f6b0bfc43e4","c7fe0b2285004152bfc8c5855f1564be","f3130a60fde84100b94c23086b11fb56","ef10f0134d3b4efea03790caa9d5f2de","97e03f8a25c1432f9fe820568004b511","bfc6f4230af648daa45a402f4accc2f0","805bab5b326345959a926fc6d762ea09","75a9a08a14ac4484bf94f6a292315adf","fca9a7f1b5e74843b19a9bf1cb7ddfa1","07ef43df173c4288bcc2b90519e991ae","b5cd87d929db409397fbcfd73fccad24","edd72461983244399ce905480e6edb1e"]},"executionInfo":{"elapsed":36771,"status":"ok","timestamp":1688719181826,"user":{"displayName":"최태순","userId":"04818132344604401268"},"user_tz":-540},"id":"5PHmKJeQQV-i","outputId":"26c0442a-0875-4531-e86d-c40959d2e7c7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec2fa8e83ee3456d9dcbcd5129bd49ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/682k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082e197443d44210ab18d672cb01acf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba2a4260e524873874dab9eff88d9a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6165df4faa4463f933c785704878368"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7fe0b2285004152bfc8c5855f1564be"}},"metadata":{}}],"source":["sum_text = summarization(input)"]},{"cell_type":"code","source":["# 예시\n","sum_text = '문재인 아들이 비리 의혹이 있다.'\n","sum_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3IGxORHLge8N","executionInfo":{"status":"ok","timestamp":1688719245085,"user_tz":-540,"elapsed":6,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"947c99e6-5784-42dc-e818-637fe4075f34"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'문재인 아들이 비리 의혹이 있다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"ILBcZSEOmVBZ"},"source":["###2. STS 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUwUuxpVQWEH"},"outputs":[],"source":["def train_sts():\n","  # GPU - A100\n","\n","  # 모델 학습\n","  logging.basicConfig(\n","\n","      format=\"%(asctime)s - %(message)s\",\n","      datefmt=\"%Y-%m-%d %H:%M:%S\",\n","      level=logging.INFO,\n","      handlers=[LoggingHandler()],\n","      )\n","  model_name = \"klue/roberta-base\"\n","\n","  train_batch_size = 32\n","  num_epochs = 4\n","  model_save_path = \"output/training_klue_sts_\" + model_name.replace(\"/\", \"-\") + \"-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","\n","  embedding_model = models.Transformer(model_name)\n","\n","  pooler = models.Pooling(\n","      embedding_model.get_word_embedding_dimension(),\n","      pooling_mode_mean_tokens=True,\n","      pooling_mode_cls_token=False,\n","      pooling_mode_max_tokens=False,\n","      )\n","\n","  model_STS = SentenceTransformer(modules=[embedding_model, pooler])\n","\n","  datasets = load_dataset(\"klue\", \"sts\")\n","  testsets = load_dataset(\"kor_nlu\", \"sts\")\n","\n","  train_samples = []\n","  dev_samples = []\n","  test_samples = []\n","\n","  for phase in [\"train\", \"validation\"]:\n","      examples = datasets[phase]\n","\n","      for example in examples:\n","          score = float(example[\"labels\"][\"label\"]) / 5.0\n","\n","          inp_example = InputExample(\n","              texts=[example[\"sentence1\"], example[\"sentence2\"]],\n","              label=score,\n","              )\n","\n","          if phase == \"validation\":\n","              dev_samples.append(inp_example)\n","          else:\n","              train_samples.append(inp_example)\n","\n","  for example in testsets[\"test\"]:\n","      score = float(example[\"score\"]) / 5.0\n","\n","      if example[\"sentence1\"] and example[\"sentence2\"]:\n","          inp_example = InputExample(\n","              texts=[example[\"sentence1\"], example[\"sentence2\"]],\n","              label=score,\n","              )\n","\n","      test_samples.append(inp_example)\n","\n","  train_dataloader = DataLoader(\n","      train_samples,\n","      shuffle=True,\n","      batch_size=train_batch_size,\n","      )\n","  train_loss = losses.CosineSimilarityLoss(model=model_STS)\n","\n","  evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n","      dev_samples,\n","      name=\"sts-dev\",\n","      )\n","\n","  warmup_steps = math.ceil(len(train_dataloader) * num_epochs  * 0.1)  # 10% of train data for warm-up\n","  logging.info(f\"Warmup-steps: {warmup_steps}\")\n","\n","  model_STS.fit(\n","      train_objectives=[(train_dataloader, train_loss)],\n","      evaluator=evaluator,\n","      epochs=num_epochs,\n","      evaluation_steps=1000,\n","      warmup_steps=warmup_steps,\n","      output_path=model_save_path)\n","\n","  #모델 저장\n","  torch.save(model_STS, f'/content/drive/MyDrive/conference/model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d32519b3854f4a6eaeaf12045d3d3f94","5009f4b20a3a4ce5b79f00193ec9c475","2e78c31fd1f94555ab296c0d99b68d98","5cc1c070a0ab431e98a17931bbd2c6f2","489aa988f3f84dcd8b48d3ee77919db3","badfbc82656f4d6dbe500c393ea202ce","6f877e13cef5475384e0bc41541c030f","4c8e745c6411411dbda79946da4100fa","b9a108ceb6c44d8eaf48c4d2c532dd89","db83730894664aaa8a0e5b8b1d642ad4","497471908ecb450f9ef5784a1b075e84","9fb282dcf5af40fe8c02f694b30e67a8","93c5df378afa473bb7cea13d76a69d8f","2c7b03c0d6094f9598c1b02a3d71baaa","68acf86a66b843e9bbfd67644b919d84","0d08dae98f0d46bea36483fa9782c928","3bc0de35f30a4cf8856780646cbbd9c2","603234b43a3a4d64a5d1688e7587c9bd","4fc7a803b8b845c1af37e5e92c64918b","44823b16972342cc979b5052cab4ce33","8d1770372a094b15ae5fa972a4013e91","483747cc00d449e38420854740928e23","15e7c70454c24fe7bc499d3119cf4a91","aef15bb931bf480b8f80abcb6c2f88dd","c0eef193c6e340dbb9829b6ec18c0a97","b5c82ac248324d5887109bc1c7918f34","68d88a0aabaa40c1a99e761bd71ff7f6","a75ea477c22c42989b0268ddc4cd0489","ff7c6f5fc6774a079aedde732532a90f","4d23e4f577c149888a932f9c0583764e","4065c054059d49e29cea56cfed8c8df0","2d12c48cedd34b9587c0725f5d6fb90e","ed44637f7bb54cc49e6aead6cc6c4137","8ce9866f9581488d925cca57958765ad","cf1d13058a7441e9bc58115f9dc238bf","174f11e8a29e4650986208d77ab8d17b","aadbd53bcae448b99b6ccd4d60d17b63","aa93318977874a2593c93a16e1d4d3e1","b24303489e264d2d91b13c0d132a7168","06ee654733af4909a3410ac162b99fa9","684e7a7dab8a45118c43b21485c7f0a0","ddac6a554ef14594b1be0d19ca9da634","d1a6b97caa1b4e7d8c5978020dfb2634","c6eaf579cf324e95aa3cb90712bed6a8","0ed45668e6be4cd5bb8c3ef4f181f49b","409c6f7c68ee4cfcb97f368ba6f259b5","219d3720ff0045ba8d578d6a4e8e6de0","4a7dd72badb545518fbdc865ec5e04d3","c247a77662944f899ea8ef07fd6ec59a","1e3a592d4f86406cab6f7f75cccd8e71","ea6bec0294fe4944a50099663cbe71a9","a9d33fad94ac4543aded61a9b7a6f80f","85e9af0414194afa84d13a0a2421241d","bfe0defacd1f447c9ce614f9677890db","56c85f7eb2ed4add91a9bf63904a8f19","61db5ef4e6234e9eb9e6a125a2663670","e1c1e27e14964b45a2aac4d75a3e9046","2800275fecc94778bf3890682d8f6352","1efc5b7f18a24006b28b085f7386b3f5","4ef5c2717e2140cc9f498017404c908a","b54b3d41388a476887060d3012c36a59","6ffedaa3afcf4027b9de926519d7c098","4ee969b95dd64f2dada61d0a50001078","0d339cb6bad047d09a4596bccc266848","58bfe0eb46054e928e957d642d39eb00","cfe9df789bd94013b7cdbe42398432c6","defd53f650894a75bff27d7b7dd95f43","2c0625d3deb947049400e2e0fd6a7759","05e490f9455549c69cc01d69a4efc90b","761e30a88dea43379f35be7ba27a38f2","aa423e4e104a40de924d18d66505b56d","228f722444844d3db47cc106076e6a60","d0674312d3fc42f5bde55587836700a9","c6041d131631405f810f3c8b4028ffbe","772d635865ad421eb706f40555d6bd4b","82a86b34261944a78c1ecc28794c8d69","2137d57adce448b18b8bb434edb141f5","f1c7ec0ec860452d8dd1b55ce72897c5","8cf67c0912c84b3f9bfccafc14e8a845","8e2a12b49e8743d3b6bc073f48c6fbd1","89e83e7014c34d39a7261946a30f7de0","c5e0361d7f7f4d71919c270a2e08ffa4","03464083a70e48829d0fc88eb561f256","e69d4c0398434470a16f1cfca27c9778","5d0cf1b979224a0b9a7d6a126d8df182","d94e6340c28d4f50a1da73130313a908","2f4aded148d34e59b93f8326fb103f2c","9cbfac9cbd7643a8ba42f6fb1b9b1b6c","23467307b60d4fc4a3994086b5d1804f","1c65af768e7046c7947e4e55b14d32e0","e15fae24ac414a06bbe410b6daaa40ae","03d101b6637c4b589d9fcc3b6c932b17","092d642910f14c21a9f9937907ffcbce","9d3089acd2034898855a7eb82c68c12c","76e0f11aee484d13be4bfe5256e6034f","88daf189b21246d3a4ee48d3419e1b8d","73bda533544a47828bf4dd2810d3b35a","5e489f009ef4436b82a2eda9986caedf","27653b9069fc4aeeac1dcf1101cf83e6","b1cefa8458bc48aea8b585500b3a3544","74ca72202ccb4241b91945ee31c4705c","f9a9a90b43694be0a9757968d2ff7eb8","54b562d6bb814ef09966355ee9713edd","36ea71529819414dbd2151a2b78ed05e","43bfb115c32645c1838c522725cd17a4","8966713065ec492e9fc001798338b09e","97a69ad7b2c64c7cbfe935fdca090166","b5b733a5ebb5402f8120349c87d3de7c","7913e2276a934fe99930184afa5bc8a4","0eefb3b8a7b44592bb299047353b2a25","06ba29fe21a942f7bc7a108103d987b4","3edd0743fae443bbb8665034ba824f1d","b1b9e2ecc6f9481aab3328ddeb3efd25","ba14dbe0c01d4cd3b9616cfca6319d69","ac70d7d78adf4d16aa94bef356f93d50","94631654b70b4da8b02b6f98e98ed5f0","73797899185d4e50805be0d1e7449892","f89e51e7b9be4800a42514a33cef5bdb","c1ab1cc098ed47d6ab853333008685dd","0006f8da4b274d1a8cd99d60f6801b3c","b772c26d2d7943b1aa059fc1beca45a8","12e530234bb74ddba2761dfd2879125f","61ba8545166f4a61ba1afdadf78ba3d6","20928927463847668809976ca8220c96","0f80da7f0e324c28ae7869238ab072ca","1128ff176f9d402bbd14e4e6983505b3","d9cc3e552148466c85b0962df48abadf","1a8b68eb470342fe831818b2e34b33f5","c48961eca76f49e88b2c57b832facfea","8569ec843b1b46748927ee87f0d6456c","0f2d86a1d8e4499e8752e7a8c000c885","cecc6e907425414cbe3d809d032e9586","d5254fa373554b1b866d528e8157eefa","c4e283c1bcf6431fa10e60c34b5782f7","428495ee92c24809b7bd520c3a7c4cca","1e60a130eb52476f9c89173ec4041880","7c8c85b5d7b14d82b6cb63d4f1be0583","cfdc8f3c4ebd4c688133255750e16c4f","bb1ea0d6da134434a65d79b9eea08a36","c17c5e4f183e4cef9402f9f7f4ebe6c6","9d25d1f2af3149b09af0dbd3e6a38467","6433f0bb93ab49f0b9e585fc0393d2fe","de18313c2e9d4fa88bc60667c368a17f","1d58e04627374937a6b3cfdf61320340","37aedba6686c447abf3d0b8415dc6502","36a29eab088647a990dc3a24a346815d","81b2aca2d79f47c4accaf090066b7ccf","2811c44a8c864154a8c65f2bdfaed7cd","202a4ee8e29349158babfc5c900afafe","c129a5c7cf31494882aab05ff2f86713","587975b5c4234431a4b42a5231e94922","1d352d246ec3471eaebec89d109438df","de77fadf3c0a4a288943c098300bf26e","148e63932ab04d5d8666e91e5d8cfd50","a95b61d842784cb7b51deda98bd00745","f943490725904059bda978bf7dd67f59","488fb29876b34fe7bf0ec1c701827696","1249fb5031e64d40859569daea47a1f8","a0370bf833c8488f84ded1fc704c50ba","af70e12111b74b1084d03cb80a105474","1a0fc602b2d849e8903ccba9edd71041","9dc26bb09686492bbf752e3a84d85fb3","80f18ff61ced49db9fdf49e5a8a457f0","fd912051f731452594d0e312fe3ac34b","438045ea4b6549078d93d2b020a1d43d","862604c59c3e45a89da4b644f8078c02","4977a55437cc4eb59a6176f2a1a4a343","9fe248f6918d4064b93da4f1e38cf4f2","4b317862f85043b4a4179506e7f879c7","bd716c0b65134f66a4acde82da6744bf","7c44817b56b14d98989505582d0ae356","e08e6360598b475282b3eb79e45aec4b","141456bd4bc146fba62adbc8368e99c3","ec0ff6e697c148efb6c149dff8cbe391","c2f544eb35e34250b6414f8f961f7d92","3bb2d1a4d8d94e37a369171340ef8768","e026d8fd18844b95b672980000b3cdeb","cee8371dff004a86a61db14f3487ad44","9a32da156d5043659a27d4d2fbd9a639","da8501eb6eff4735b331bfc048ffef5a","7af704768e1f46c1b7317341c1d85d70","043285b2a1ce4b708e8f56ce59162186","887d247c18a7450da680805cbe2fce24","15bac582ba51469699cb557ccad56713","17b2f83d518b4a65bb296d60687244f4","caf9e3c4682549e3876e4c7dfae98345","aa1fbeb813414358888c3d0aebc9170e","ca6fb435fc844b0a8f2707d3111f24db","2779fd55d2154bd5a398a19903fad5cd","a75df5876ea147769cb56570a62883d3","089b6f2aac474b39afbaf25ba25014df","d5227d3ef3f9431e917efbf2f4a2880f","b503610d54c545f0a4e5fb8c8733a6d0","7377fc2f13de493a902c436f57b0212b","2cb6e937cc18477fb3663c95f0c0c9ed","91e2e005f6ce493d9d3dff4bacaeffe7","cd81f92a79d34f93a6bd7875ebc8e3dd","cc13800bd9004aee924b556a29837f79","8a547db21fbf4e46b2bf77a4a2bd89fc","a54b17f842064798b3438d517a46797e","583958d87eb64b95b5599d8f91170c27","77513903a98544a18b6a2eeaa446c558","73c16c93b59641e5bfa9526329bc168d","d870704150fc4a03b23cdbb4acba4cbc","a9984b7e6d7f46d299db0e2e1556c701","afd98008d90441e49987e1f2bbee7e76","e41c1f3fb5654e68a616379841a80772","01d0a633b1454b96a2bf5a133827a753","83826187d63047e089be47b11b2eb292","ad58dfb13f604c83afa67ae11be19e34","46868d0c26a249c893b197d9fd879d9c","7b5942bcad064fddb9ee7baad69357a8","0e48a647feac4a6fa8e1b0ca7e0dd5d8","5a1758281aaa425784feb6690a88cbfe","8500a876efb243a8add61def6b4bb6ce","f885ee6533234711aede56552455ba7a","8d8d17de01d34518a17864c88fae22cc","122837f925b546948451a4705d923b14","6e40ed491d694abc817d1f61369a4514","9fe237d11af24ee591a185ec12c7b308","4193e2bb562f4d37808bc5690dab397b","edc0980703c94405ab2eaacc36f26d42","b746dacf53af401da5b2abcb322cbd68","f036925a4a784cc980a65d3016e9f18e","6d86c753277044c0a3f3779a0a202d50","c5d8f7407c44406bb2db929348b97fa9","34e37c182d4b4080916884be8a210e6c","bf4ff2dfb5ad48f980e4d7cb8f16bec1","a76665ebafc7443ba2ac383cf45507e7","df7637c293044972be7563064dd28684","de58cabbdeee4455a11ac9d7a7b89097","d4226c1ba0a9485abf1bf58aa9eee7ed","15fb0cd0e22945b887145b79e56dd960","2c26d07687774d0383e28f8a5a721db0","80981d274d544fc6a4f24db2966eef3e","0e7df481bcbb437a8889908e4f6a4632","77c37aa6b2d442b29e5ee5bd891bf534","647e9f350a9b42bfa35aa4a41e619e87","d3be52b3ffa149caa458fdb9b492c563","981139bcb5ac444899c304a725ef85d4","7e363a7b7c904d4093544495ff8dd922","5ab80ca01b3b49c182b6e829818d6a00","cbafb99c99ce47469e0527ddfbe963b4","69d1303e89454305ae76643db65ea87e","f3d1404dd63f46508b8e4452b9489b43","727e387c873d4c06a297a62e701d13e1","1bb8a24204484916a15bbd084de686a9","f828951eee9441dd90882cfb77fd825c","81cb3833113e4006a9623c1826a58eb7","6e739b3eee9c4af78f520990b2408a08","41367c1e8d2c4850865a8b79d2ec9e19","869cdf0b387147dcbec54b75234b3f75","340cfaf7363d4bc9b8652419dc81d56f","7b63e0a6b333495d9fffca12f4b6f045","570c0012f01d45f28b3d505125a363df","4235145f595f4021973b82cb70a7cd93","38f9812eb26b4d17821434ddf5e7896a","cc96ec39d44841a39cfe481816869e48","64fc140787714327b389249fc3964e8c","8d6372369c444419884d79cdb01950a9","7ac43b2c69764b70af37b4b11227f242","3dc2ecf1bdab4399825bbe20e1aae24b","d77d0f51df7f4a0facd782e991d6bf71","a8ccf90da77b4759889432899759c982","65bbf9a52b0f4da58380c96b6fd88ce1","e6af8e666b3f41e1b5c0bbea8fdea472","b16f97a68fbf46f3a1a20ca3179d857a","1e3e13d92a704455b70460dbc91e7ad2","5699fb4d6c46438aba09145effe5581c","1db41e74ebd549c28ff3b5022cc2bfd4","8bef31eedbdb49e4a6a461633ca07070","a551d0c5dacb4c1a9ce1b1b1b2f8cae7","ae689c6f2f99438a9033d4a1555e03b4","f423ea39e1154a708767dca51c2db715","2758a26da8c5457588d7449094813ca5","cc0d3e946ee64115b29e9e150b218e4e","bc4c0228fc2b4bedaa4fb2d589a6499c","0eb45fccf734497487e4041e433f5c4a","ba54ebc974754c059d78c8e3cdeffea4","923581a68e63436ca29052473a3aaab7","8d0d2b7f8ccd499ba5a0021ce95656e7","ed5e1f832af143f3abff3ff65ccdb60c","e532386aa47841eab3762ff2f114a00a","b840375bf51443e4b57df2941ec335f8","ecb747ac89fc4a3087b133b78ed201e1","6af56822a0cb489f8f144cfa49454063","2d2e26a0e90c476aa595edb3ab794c58","f01ddf8b05fb430e911ef63364be6415","cbc75573afdc4d7ba95432d430e1189b","a1ccf70cb614454e92a0f69ea83680ae","3a3989f3cb2e4d12b0f6e0ffc9a17a89","1fcc5b88b31e4543a12e69f13081f868","fa6adf56c3ae46e09b5e949f8b104c3c","30b0dfffed60454d82b8c6d9ca041423","7ca593d5ace841efa79687005ce0024b","c71897b5c5054750b2e8c0ea19ef954c","c0deba1add104a599a31e2b6e384eb30","b358cc12cf244d58aef735e1ee98b773","0e5e89d5899b4343ae7c530cea3ace1f","cbf1f109e39c47d2a31ee09d7e672664","d2e032f2fb864a638cfda3bc84d63ecd","9d3d22e33be843bc9a786442a08c64b1","92bac75244514dc9936de5ff0d156b50","6f7da9ff03774a73859008a3fd8a9c4c","ce6b26e7204945bfb91730fd864c9d61","59825cfda8c84e6e9196f0da844d7729","97b968c8edbc4e99ab572fc7dcc28e49","2f70744b9d8b42cf9bea81b6dbe08239"]},"executionInfo":{"elapsed":735883,"status":"ok","timestamp":1688641427756,"user":{"displayName":"최태순","userId":"04818132344604401268"},"user_tz":-540},"id":"In6BidX5ZxX4","outputId":"317a7a95-6c0e-4209-fb34-944ce1c5273d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32519b3854f4a6eaeaf12045d3d3f94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fb282dcf5af40fe8c02f694b30e67a8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e7c70454c24fe7bc499d3119cf4a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce9866f9581488d925cca57958765ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed45668e6be4cd5bb8c3ef4f181f49b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61db5ef4e6234e9eb9e6a125a2663670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/23.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defd53f650894a75bff27d7b7dd95f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/22.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c7ec0ec860452d8dd1b55ce72897c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/21.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23467307b60d4fc4a3994086b5d1804f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset klue/sts to /root/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1cefa8458bc48aea8b585500b3a3544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/11668 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ba29fe21a942f7bc7a108103d987b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/519 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e530234bb74ddba2761dfd2879125f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset klue downloaded and prepared to /root/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5254fa373554b1b866d528e8157eefa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d58e04627374937a6b3cfdf61320340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95b61d842784cb7b51deda98bd00745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/4.57k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"862604c59c3e45a89da4b644f8078c02"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset kor_nlu/sts to /root/.cache/huggingface/datasets/kor_nlu/sts/1.0.0/4facbba77df60b0658056ced2052633e681a50187b9428bd5752ebd59d332ba8...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/282k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e026d8fd18844b95b672980000b3cdeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/89.9k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6fb435fc844b0a8f2707d3111f24db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/66.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a547db21fbf4e46b2bf77a4a2bd89fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/5703 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad58dfb13f604c83afa67ae11be19e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/1471 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4193e2bb562f4d37808bc5690dab397b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4226c1ba0a9485abf1bf58aa9eee7ed"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset kor_nlu downloaded and prepared to /root/.cache/huggingface/datasets/kor_nlu/sts/1.0.0/4facbba77df60b0658056ced2052633e681a50187b9428bd5752ebd59d332ba8. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbafb99c99ce47469e0527ddfbe963b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b63e0a6b333495d9fffca12f4b6f045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65bbf9a52b0f4da58380c96b6fd88ce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc0d3e946ee64115b29e9e150b218e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2e26a0e90c476aa595edb3ab794c58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b358cc12cf244d58aef735e1ee98b773"}},"metadata":{}}],"source":["train_sts()"]},{"cell_type":"markdown","metadata":{"id":"-K9mYGKmmied"},"source":["###3. 요약문장 STS 모델 학습 후 유사도 문장 선정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUYCyz2nZ9yA"},"outputs":[],"source":["def test_sts(query, top_k):\n","  # 모델 설정\n","  model = torch.load('/content/drive/MyDrive/conference/model.pt')\n","\n","  # 데이터 불러오기\n","  data = pd.read_csv('/content/drive/MyDrive/conference/final_data.csv', encoding='utf-8')\n","  # 비교 데이터 설정\n","  content = []\n","  for i in range(len(data)):\n","\n","    content.append(str(data['contents'][i]))\n","\n","  document_embeddings = model.encode(content)\n","\n","  # 입력 데이터\n","  query_embedding = model.encode(query)\n","\n","  # 입력 문장 - 문장 후보군 간 코사인 유사도 계산\n","  cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n","\n","  # 코사인 유사도 순으로 `top_k` 개 문장 추출\n","  top_results = torch.topk(cos_scores, k=top_k)\n","\n","  num_top_results = sum(top_results[0] > 0.5)\n","\n","  global cos_contents\n","  global label_contents\n","  cos_contents = []\n","  label_contents = []\n","\n","  if num_top_results != 0:\n","    print(f\"입력 문장: {query}\")\n","    print(f\"\\n<입력 문장과 유사한 {num_top_results} 개의 문장>\\n\")\n","\n","    for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n","      if score <= 0.5: break\n","      label = 'True' if data['label'][int(idx)] == 1 else 'False'\n","      cos_contents.append(content[idx])\n","      label_contents.append(label)\n","      print(f\"{i+1}: {content[idx]} {'(유사도: {:.4f})'.format(score)} {'(진실 여부:{})'.format(label)}\\n\")\n","\n","    cos_contents = cos_contents[0]\n","    label_contents = label_contents[0]\n","\n","  elif num_top_results == 0:\n","    print(f\"입력 문장: {query}\")\n","    print(f\"\\n입력 문장과 유사한 문장이 {num_top_results} 개이므로 확인 불가합니다.\\n\")\n","#비슷한 주제 팩트"]},{"cell_type":"code","source":["def klue_nli(query, text_list):\n","  classifier = pipeline(\n","      \"text-classification\",\n","      model=\"Huffon/klue-roberta-base-nli\",\n","      return_all_scores=True)\n","  tokenizer = AutoTokenizer.from_pretrained(\"Huffon/klue-roberta-base-nli\")\n","\n","  global results\n","  results = classifier(f'{query} {tokenizer.sep_token} {text_list}')[0]\n","  return results"],"metadata":{"id":"pbplgO308tJN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def final_result(query, text, label_info, result):\n","  score_list = [ d['score'] for d in result]\n","  score_list\n","\n","  if score_list.index(max(score_list)) == 1:\n","    score_list.sort(reverse=True)\n","    label_score = score_list[1]\n","    label = [item['label'] for item in result if item['score'] == label_score][0]\n","\n","    if label == 'ENTAILMENT':\n","      print(\"label 결과가 {0}(수반)이므로 '{1}'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '{2}'과 동일하게 {3}로 결정된다.\".format(label, query, text, label_info))\n","    elif label == 'CONTRADICTION':\n","      if label_info == 'True':\n","        label_info = 'False'\n","      else:\n","        label_info = 'True'\n","      print(\"label 결과가 {0}(모순)이므로 '{1}'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '{2}'와는 다르게 {3}로 결정된다.\".format(label, query, text, label_info))\n","\n","  else:\n","    score_list.sort(reverse=True)\n","    label_score = score_list[0]\n","    label = [item['label'] for item in result if item['score'] == label_score][0]\n","    if label == 'ENTAILMENT':\n","      print(\"label 결과가 {0}(수반)이므로 '{1}'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '{2}'과 동일하게 {3}로 결정된다.\".format(label, query, text, label_info))\n","    else:\n","      if label_info == 'True':\n","        label_info = 'False'\n","      else:\n","        label_info = 'True'\n","      print(\"label 결과가 {0}(모순)이므로 '{1}'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '{2}'와는 다르게 {3}로 결정된다.\".format(label, query, text, label_info))\n","\n","  if (label == 'CONTRADICTION') & (label_info == 'False'):\n","    print(\"\\n 따라서 올바른 문장은 '{0}'이다.\".format(text))"],"metadata":{"id":"WmT97X3lhZw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# query = sum_text, text = cos_contents, label = label_contents, result = results"],"metadata":{"id":"-A56yTSPhZzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sts return 값\n","test_sts(sum_text, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGTCBWj3WfDh","executionInfo":{"status":"ok","timestamp":1688723876320,"user_tz":-540,"elapsed":16435,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"1d96cc94-a241-4be7-ce8e-e3f2f01bc1c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: 문재인 아들이 비리 의혹이 있다고 한다.\n","\n","<입력 문장과 유사한 2 개의 문장>\n","\n","1: 안철수 문재인 아들 5급 공무원에 특채는 사실 (유사도: 0.5470) (진실 여부:False)\n","\n","2: 문재인 민주당 후보 아들이 고용정보원에서 휴직 중 승진했다 는 의혹  (유사도: 0.5393) (진실 여부:False)\n","\n"]}]},{"cell_type":"code","source":["# sts 이후 사용해야할 내용\n","cos_contents, label_contents"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kDVsiKzWpo4","executionInfo":{"status":"ok","timestamp":1688723876320,"user_tz":-540,"elapsed":13,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"e33c6970-f71c-47df-968f-4ed454378690"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('안철수 문재인 아들 5급 공무원에 특채는 사실', 'False')"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["# nli return 값\n","klue_nli(sum_text, cos_contents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9aJ50zRYgs3","executionInfo":{"status":"ok","timestamp":1688723878465,"user_tz":-540,"elapsed":2155,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"d95c3283-0a3d-4ac4-85cd-6dc16f06078b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ENTAILMENT', 'score': 0.0005115066305734217},\n"," {'label': 'NEUTRAL', 'score': 0.9991310238838196},\n"," {'label': 'CONTRADICTION', 'score': 0.0003574293805286288}]"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["# nli 이후 사용해야할 내용\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXMbRamuZBRg","executionInfo":{"status":"ok","timestamp":1688723878466,"user_tz":-540,"elapsed":10,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"306367b5-9853-4008-f083-610775a98ebb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ENTAILMENT', 'score': 0.0005115066305734217},\n"," {'label': 'NEUTRAL', 'score': 0.9991310238838196},\n"," {'label': 'CONTRADICTION', 'score': 0.0003574293805286288}]"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["final_result(sum_text, cos_contents, label_contents, results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AI4IajURkZte","executionInfo":{"status":"ok","timestamp":1688723933339,"user_tz":-540,"elapsed":483,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"f215a0a4-26cc-49c8-b6f8-758aef0cdc62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label 결과가 ENTAILMENT(수반)이므로 '문재인 아들이 비리 의혹이 있다고 한다.'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '안철수 문재인 아들 5급 공무원에 특채는 사실'과 동일하게 False로 결정된다.\n"]}]},{"cell_type":"markdown","source":["#### 예시"],"metadata":{"id":"C4_g80GZf_ib"}},{"cell_type":"code","source":["# 예시 1\n","sum_text = '중랑구에서는 서울장미축제를 개최하지 않는다'\n","test_sts(sum_text, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5D5msXmC8QO0","executionInfo":{"status":"ok","timestamp":1688723958787,"user_tz":-540,"elapsed":17066,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"39392681-5d62-4f1b-bc69-182d314a10ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: 중랑구에서는 서울장미축제를 개최하지 않는다\n","\n","<입력 문장과 유사한 1 개의 문장>\n","\n","1: 중랑구는 꽃과 문화예술 먹거리가 어우러진 동네 혹은 지역 대표축제인 서울장미축제를 28일까지 개최한다. (유사도: 0.6744) (진실 여부:True)\n","\n"]}]},{"cell_type":"code","source":["klue_nli(sum_text, cos_contents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awXF3diOo24S","executionInfo":{"status":"ok","timestamp":1688723960456,"user_tz":-540,"elapsed":1683,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"a14f2d42-5831-4afb-9046-7d834f58f17c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ENTAILMENT', 'score': 0.00029482197714969516},\n"," {'label': 'NEUTRAL', 'score': 0.036649733781814575},\n"," {'label': 'CONTRADICTION', 'score': 0.9630554914474487}]"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["final_result(sum_text, cos_contents, label_contents, results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXJHGl6co26v","executionInfo":{"status":"ok","timestamp":1688724033736,"user_tz":-540,"elapsed":477,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"3a035dcf-aaec-415c-93ba-3db7025081bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label 결과가 CONTRADICTION(모순)이므로 '중랑구에서는 서울장미축제를 개최하지 않는다'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '중랑구는 꽃과 문화예술 먹거리가 어우러진 동네 혹은 지역 대표축제인 서울장미축제를 28일까지 개최한다.'와는 다르게 False로 결정된다.\n","\n"," 따라서 올바른 문장은 '중랑구는 꽃과 문화예술 먹거리가 어우러진 동네 혹은 지역 대표축제인 서울장미축제를 28일까지 개최한다.'이다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Nq3v3QYlo29L"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16383,"status":"ok","timestamp":1688722067426,"user":{"displayName":"최태순","userId":"04818132344604401268"},"user_tz":-540},"id":"Jm3Llp8_j1BQ","outputId":"9eb8ae86-f420-4e2a-a178-cde36077c30c"},"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: 문재인 아들이 비리 의혹이 없다.\n","\n","<입력 문장과 유사한 1 개의 문장>\n","\n","1: 안철수 문재인 아들 5급 공무원에 특채는 사실 (유사도: 0.5352) (진실 여부:False)\n","\n"]}],"source":["# 예시 2 - 유사도 문장이 거짓이 나옴 -> 긍/부정에서는 contradiction(모순)이 더 높게 나옴 -> 따라서 실제 input은 거짓이 아니라 사실임.\n","sum_text = '문재인 아들이 비리 의혹이 없다.'\n","test_sts(sum_text, 3)\n","# 중랑구는 꽃과 문화예술 먹거리가 어우러진 동네 혹은 지역 대표축제인 서울장미축제를 28일까지 개최한다.\n","# 위의 실제 문장을 '중랑구는 서울장미축제를 28일까지 개최하지 않는다'"]},{"cell_type":"code","source":["klue_nli(sum_text, cos_contents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wr-w0ux5qiuJ","executionInfo":{"status":"ok","timestamp":1688722068828,"user_tz":-540,"elapsed":1415,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"2fd45fde-0cfa-4fe5-bb47-5ffc400279dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ENTAILMENT', 'score': 0.00033529079519212246},\n"," {'label': 'NEUTRAL', 'score': 0.9987083673477173},\n"," {'label': 'CONTRADICTION', 'score': 0.0009563304483890533}]"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["final_result(sum_text, cos_contents, label_contents, results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylxLNvkLqizN","executionInfo":{"status":"ok","timestamp":1688722068828,"user_tz":-540,"elapsed":6,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"f434a341-e232-4fea-aa5c-4372f49e0e6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label 결과가 CONTRADICTION(모순)이므로 '문재인 아들이 비리 의혹이 없다.'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '안철수 문재인 아들 5급 공무원에 특채는 사실'와는 다르게 True로 결정된다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bD5mJDlmtXl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예시 3\n","sum_text = '문재인 아들이 비리 의혹이 있다고 한다.'\n","test_sts(sum_text, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gALcuU-tXzi","executionInfo":{"status":"ok","timestamp":1688722672342,"user_tz":-540,"elapsed":16131,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"d84e5356-6591-45a8-b15d-b817d97febcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 문장: 문재인 아들이 비리 의혹이 있다고 한다.\n","\n","<입력 문장과 유사한 2 개의 문장>\n","\n","1: 안철수 문재인 아들 5급 공무원에 특채는 사실 (유사도: 0.5470) (진실 여부:False)\n","\n","2: 문재인 민주당 후보 아들이 고용정보원에서 휴직 중 승진했다 는 의혹  (유사도: 0.5393) (진실 여부:False)\n","\n"]}]},{"cell_type":"code","source":["klue_nli(sum_text, cos_contents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUUX_7fDtcsp","executionInfo":{"status":"ok","timestamp":1688722673817,"user_tz":-540,"elapsed":1491,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"f4a22f0c-c04b-4071-c807-f21e4f053a6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'ENTAILMENT', 'score': 0.0005115066305734217},\n"," {'label': 'NEUTRAL', 'score': 0.9991310238838196},\n"," {'label': 'CONTRADICTION', 'score': 0.0003574293805286288}]"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["final_result(sum_text, cos_contents, label_contents, results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m00H83g5tcvC","executionInfo":{"status":"ok","timestamp":1688722673817,"user_tz":-540,"elapsed":7,"user":{"displayName":"최태순","userId":"04818132344604401268"}},"outputId":"58b1337c-c01b-4f64-f9ba-c39368712be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label 결과가 ENTAILMENT(수반)이므로 '문재인 아들이 비리 의혹이 있다고 한다.'문장에 대한 최종 결과는 유사도가 가장 높은 문장인 '안철수 문재인 아들 5급 공무원에 특채는 사실'과 동일하게 False로 결정된다.\n"]}]}]}