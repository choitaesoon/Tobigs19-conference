{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "['국민일보' '동아일보' '조선일보' '중앙일보' '매일경제' '파이낸셜뉴스' '한국경제' '한국일보' '머니투데이' '아주경제'\n",
      " '일간스포츠' '서울경제' '아시아경제' '스포츠조선' '세계일보' '헤럴드경제' '스포츠월드' '문화일보' '서울신문'\n",
      " '아시아투데이' '스포츠동아' '스포츠서울' '경향신문' '내일신문' '이투데이' '스포츠경향' '경북일보' '경상일보'\n",
      " '경기일보' '매일신문' '부산일보' '경기신문' '경남일보' '대구일보' '대전일보' '영남일보' '전북일보' '중도일보'\n",
      " '충청투데이' '한라일보' '강원일보' '경남신문' '경인일보' '광주일보' '전북도민일보' '전자신문' '강원도민일보'\n",
      " '중부매일' '해럴드경제' '경북신문' '제주일보' '전라일보' '한겨레' '전남일보' '무등일보' '광남일보' '국제신문'\n",
      " '디지털타임스' '경남도민일보' '인천일보' '한국스포츠경제' '데일리스포츠한국' '이데일리' '제민일보' '중부일보'\n",
      " '뉴제주일보']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seenw\\AppData\\Local\\Temp\\ipykernel_7996\\2650894740.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['매체명'] = data_cleaned['매체명'].apply(lambda x: x.replace('\\n', ''))\n",
      "C:\\Users\\seenw\\AppData\\Local\\Temp\\ipykernel_7996\\2650894740.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['매체명'] = data_cleaned['매체명'].apply(lambda x: x.replace(' ', ''))\n",
      "C:\\Users\\seenw\\AppData\\Local\\Temp\\ipykernel_7996\\2650894740.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned.drop(index, inplace=True)\n",
      "C:\\Users\\seenw\\AppData\\Local\\Temp\\ipykernel_7996\\2650894740.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['매체명'] = data_cleaned['매체명'].replace({'데일리스포':'데일리스포츠한국', '츠한국':'데일리스포츠한국', '스포츠한국':'데일리스포츠한국', '비즈앤스포':'스포츠월드', '비즈앤스포츠월드':'스포츠월드', '세계비즈앤스포츠월드':'스포츠월드', '디지털타임즈':'디지털타임스', '츠월드':'스포츠월드', '제주신보':'제주일보'})\n"
     ]
    }
   ],
   "source": [
    "# 엑셀 파일 가져오기\n",
    "data = pd.read_excel('기사형광고_최종본.xlsx', index_col=0)\n",
    "\n",
    "# 매체명, 상품명 값이 NA인 행 제거\n",
    "data_cleaned = data.dropna(subset=['매체명', '상품명'])\n",
    "\n",
    "# 매체명 전처리\n",
    "data_cleaned['매체명'] = data_cleaned['매체명'].apply(lambda x: x.replace('\\n', ''))\n",
    "data_cleaned['매체명'] = data_cleaned['매체명'].apply(lambda x: x.replace(' ', ''))\n",
    "\n",
    "# 조건에 해당하는 행 개수 각각 11개, 1개, 2개, 1개\n",
    "index = data_cleaned[data_cleaned['매체명'].isin(['신고', '매체명', '경제', '한국스포츠'])].index  \n",
    "data_cleaned.drop(index, inplace=True)\n",
    "data_cleaned['매체명'] = data_cleaned['매체명'].replace({'데일리스포':'데일리스포츠한국', '츠한국':'데일리스포츠한국', '스포츠한국':'데일리스포츠한국', '비즈앤스포':'스포츠월드', '비즈앤스포츠월드':'스포츠월드', '세계비즈앤스포츠월드':'스포츠월드', '디지털타임즈':'디지털타임스', '츠월드':'스포츠월드', '제주신보':'제주일보'})\n",
    "\n",
    "print(data_cleaned['매체명'].nunique())\n",
    "print(data_cleaned['매체명'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>매체명</th>\n",
       "      <th>게재일</th>\n",
       "      <th>광고주</th>\n",
       "      <th>연도</th>\n",
       "      <th>상품명</th>\n",
       "      <th>site</th>\n",
       "      <th>쿼리</th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>link3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24185</th>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>525</td>\n",
       "      <td>롯데주류/\\n롯데백화점 잠실점</td>\n",
       "      <td>2017</td>\n",
       "      <td>오픈다이닝 존</td>\n",
       "      <td>fnnews.com</td>\n",
       "      <td>site:fnnews.com 파이낸셜뉴스 오픈다이닝 존</td>\n",
       "      <td>http://fnnews.com/</td>\n",
       "      <td>http://fe.fnnews.com/Login/Login.aspx</td>\n",
       "      <td>https://www.fnnews.com/news/202306201334276675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24186</th>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>525</td>\n",
       "      <td>㈜신영</td>\n",
       "      <td>2017</td>\n",
       "      <td>인천 구월 지웰시티푸르지오</td>\n",
       "      <td>fnnews.com</td>\n",
       "      <td>site:fnnews.com 파이낸셜뉴스 인천 구월 지웰시티푸르지오</td>\n",
       "      <td>https://www.fnnews.com/news/202103240938223409</td>\n",
       "      <td>https://www.fnnews.com/news/201705260944469771</td>\n",
       "      <td>https://www.fnnews.com/news/201706201514181916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24187</th>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>529</td>\n",
       "      <td>아모레퍼시픽/ 파리바게뜨</td>\n",
       "      <td>2017</td>\n",
       "      <td>에뛰드하우스 명동 플래그십 스토어</td>\n",
       "      <td>fnnews.com</td>\n",
       "      <td>site:fnnews.com 파이낸셜뉴스 에뛰드하우스 명동 플래그십 스토어</td>\n",
       "      <td>https://www.fnnews.com/news/201705281655136558</td>\n",
       "      <td>https://www.fnnews.com/news/201705101713125559</td>\n",
       "      <td>https://www.fnnews.com/series/4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24188</th>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>529</td>\n",
       "      <td>아모레퍼시픽/ 파리바게뜨</td>\n",
       "      <td>2017</td>\n",
       "      <td>상 큼한 천혜향 미니외</td>\n",
       "      <td>fnnews.com</td>\n",
       "      <td>site:fnnews.com 파이낸셜뉴스 상 큼한 천혜향 미니</td>\n",
       "      <td>http://fnnews.com/</td>\n",
       "      <td>https://www.fnnews.com/news/202010220833480703</td>\n",
       "      <td>https://www.fnnews.com/news/202101271356493572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24189</th>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>530</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>2017</td>\n",
       "      <td>QLED TV 75형 2종</td>\n",
       "      <td>fnnews.com</td>\n",
       "      <td>site:fnnews.com 파이낸셜뉴스 QLED TV 75형 2종</td>\n",
       "      <td>https://www.fnnews.com/news/202203221817060637</td>\n",
       "      <td>https://www.fnnews.com/news/202111301730509264</td>\n",
       "      <td>https://www.fnnews.com/news/202203031031583539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          매체명  게재일               광고주    연도                 상품명        site  \\\n",
       "24185  파이낸셜뉴스  525  롯데주류/\\n롯데백화점 잠실점  2017             오픈다이닝 존  fnnews.com   \n",
       "24186  파이낸셜뉴스  525               ㈜신영  2017      인천 구월 지웰시티푸르지오  fnnews.com   \n",
       "24187  파이낸셜뉴스  529     아모레퍼시픽/ 파리바게뜨  2017  에뛰드하우스 명동 플래그십 스토어  fnnews.com   \n",
       "24188  파이낸셜뉴스  529     아모레퍼시픽/ 파리바게뜨  2017        상 큼한 천혜향 미니외  fnnews.com   \n",
       "24189  파이낸셜뉴스  530              삼성전자  2017      QLED TV 75형 2종  fnnews.com   \n",
       "\n",
       "                                              쿼리  \\\n",
       "24185             site:fnnews.com 파이낸셜뉴스 오픈다이닝 존   \n",
       "24186      site:fnnews.com 파이낸셜뉴스 인천 구월 지웰시티푸르지오   \n",
       "24187  site:fnnews.com 파이낸셜뉴스 에뛰드하우스 명동 플래그십 스토어   \n",
       "24188         site:fnnews.com 파이낸셜뉴스 상 큼한 천혜향 미니   \n",
       "24189      site:fnnews.com 파이낸셜뉴스 QLED TV 75형 2종   \n",
       "\n",
       "                                                link1  \\\n",
       "24185                              http://fnnews.com/   \n",
       "24186  https://www.fnnews.com/news/202103240938223409   \n",
       "24187  https://www.fnnews.com/news/201705281655136558   \n",
       "24188                              http://fnnews.com/   \n",
       "24189  https://www.fnnews.com/news/202203221817060637   \n",
       "\n",
       "                                                link2  \\\n",
       "24185           http://fe.fnnews.com/Login/Login.aspx   \n",
       "24186  https://www.fnnews.com/news/201705260944469771   \n",
       "24187  https://www.fnnews.com/news/201705101713125559   \n",
       "24188  https://www.fnnews.com/news/202010220833480703   \n",
       "24189  https://www.fnnews.com/news/202111301730509264   \n",
       "\n",
       "                                                link3  \n",
       "24185  https://www.fnnews.com/news/202306201334276675  \n",
       "24186  https://www.fnnews.com/news/201706201514181916  \n",
       "24187              https://www.fnnews.com/series/4221  \n",
       "24188  https://www.fnnews.com/news/202101271356493572  \n",
       "24189  https://www.fnnews.com/news/202203031031583539  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('result1.csv', index_col=0)\n",
    "result = pd.read_csv('result2.csv', index_col=0)\n",
    "result = pd.read_csv('result3.csv', index_col=0)\n",
    "result = pd.read_csv('result4.csv', index_col=0)\n",
    "# result = pd.read_csv('result5.csv', index_col=0)\n",
    "# result = pd.read_csv('result6.csv', index_col=0)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: 매체명, value: 사이트 기본 주소\n",
    "media2site = {\n",
    " '서울경제':'sedaily.com',\n",
    " '서울신문':'seoul.co.kr',\n",
    " '세계일보':'segye.com',\n",
    " '스포츠경향':'sports.khan.co.kr',\n",
    " '스포츠동아':'sports.donga.com',\n",
    " '스포츠서울':'sportsseoul.com',\n",
    " '스포츠월드':'sportsworldi.com',\n",
    " '스포츠조선':'sportschosun.com',\n",
    " '스포츠한국':'sports.hankooki.com',\n",
    " '아시아경제':'asiae.co.kr',\n",
    " '아시아투데이':'asiatoday.co.kr',\n",
    " '아주경제':'ajunews.com',\n",
    " '영남일보':'yeongnam.com',\n",
    " '이데일리':'edaily.co.kr',\n",
    " '이투데이':'etoday.co..kr',\n",
    " '인천일보':'incheonilbo.com',\n",
    " '일간스포츠':'isplus.com',\n",
    " '전남일보':'jnilbo.com',\n",
    " '전라일보':'jeollailbo.com',\n",
    " '전북도민일보':'domin.co.kr',\n",
    " '전북일보':'jjan.kr',\n",
    " '전자신문':'etnews.com',\n",
    " '제민일보':'cdn.jemin.com',\n",
    " '제주일보':'jejunews.com',\n",
    " '조선일보':'chosun.com',\n",
    " '중도일보':'joongdo.co.kr',\n",
    " '중부매일':'jbnews.com',\n",
    " '중부일보':'joongboo.com',\n",
    " '중앙일보':'joongang.co.kr',\n",
    " '충청투데이':'cctoday.co.kr',\n",
    " '파이낸셜뉴스':'fnnews.com',\n",
    " '한겨레':'hani.co.kr',\n",
    " '한국경제':'hankyung.com',\n",
    " '한국스포츠경제':'sporbiz.co.kr',\n",
    " '한국일보':'hankookilbo.com',\n",
    " '한라일보':'ihalla.com',\n",
    " '헤럴드경제':'biz.heraldcorp.com',\n",
    " '강원도민일보':'kado.net',\n",
    " '강원일보':'kwnews.co.kr',\n",
    " '경기신문':'kgnews.co.kr',\n",
    " '경기일보':'kyeonggi.com',\n",
    " '경남도민일보':'idomin.comr',\n",
    " '경남신문':'kwnews.co.kr',\n",
    " '경북신문':'kbsm.net',\n",
    " '경북일보':'kwnews.co.kr',\n",
    " '경상일보':'kyongbuk.co.kr',\n",
    " '경인일보':'kyeongin.com',\n",
    " '경향신문':'khan.co.kr',\n",
    " '광남일보':'gwangnam.co.kr',\n",
    " '광주일보':'kwangju.co.kr',\n",
    " '국제신문':'kookje.co.kr',\n",
    " '내일신문':'naeil.com',\n",
    " '뉴제주일보':'jejuilbo.net',\n",
    " '대구일보':'idaegu.com',\n",
    " '대전일보':'daejonilbo.com',\n",
    " '데일리스포츠한국':'dailysportshankook.co.kr',\n",
    " '디지털타임즈':'dt.co.kr',\n",
    " '매일신문':'imaeil.com',\n",
    " '무등일보':'m.mdilbo.com',\n",
    " '부산일보':'busan.com',\n",
    " '국민일보':'kmib.co.kr',\n",
    " '동아일보':'donga.com',\n",
    " '조선일보':'chosun.com',\n",
    " '중앙일보':'joongang.co.kr',\n",
    " '매일경제':'mk.co.kr',\n",
    " '파이낸셜 뉴스':'fnnews.com',\n",
    " '한국경제':'hankyung.com',\n",
    " '한국일보':'hankookilbo.com',\n",
    " '머니투데이':'mt.co.kr',\n",
    " '경남일보':'gnnews.co.kr',\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('조선일보', 1267),\n",
       " ('한국경제', 1213),\n",
       " ('중앙일보', 619),\n",
       " ('서울경제', 518),\n",
       " ('아시아투데이', 441),\n",
       " ('파이낸셜뉴스', 333),\n",
       " ('이투데이', 264),\n",
       " ('전자신문', 264),\n",
       " ('아시아경제', 254),\n",
       " ('스포츠동아', 213),\n",
       " ('헤럴드경제', 185),\n",
       " ('영남일보', 145),\n",
       " ('이데일리', 141),\n",
       " ('서울신문', 119),\n",
       " ('아주경제', 117),\n",
       " ('스포츠서울', 89),\n",
       " ('한국일보', 85),\n",
       " ('스포츠경향', 61),\n",
       " ('스포츠월드', 60),\n",
       " ('충청투데이', 60),\n",
       " ('중부일보', 50),\n",
       " ('세계일보', 46),\n",
       " ('한국스포츠경제', 36),\n",
       " ('중도일보', 31),\n",
       " ('일간스포츠', 28),\n",
       " ('전남일보', 28),\n",
       " ('스포츠조선', 13),\n",
       " ('전북도민일보', 11),\n",
       " ('한겨레', 7),\n",
       " ('인천일보', 6),\n",
       " ('전북일보', 6),\n",
       " ('제민일보', 5),\n",
       " ('제주일보', 4),\n",
       " ('한라일보', 4),\n",
       " ('전라일보', 1),\n",
       " ('중부매일', 1),\n",
       " ('스포츠한국', 0),\n",
       " ('강원도민일보', 0),\n",
       " ('강원일보', 0),\n",
       " ('경기신문', 0),\n",
       " ('경기일보', 0),\n",
       " ('경남도민일보', 0),\n",
       " ('경남신문', 0),\n",
       " ('경북신문', 0),\n",
       " ('경북일보', 0),\n",
       " ('경상일보', 0),\n",
       " ('경인일보', 0),\n",
       " ('경향신문', 0),\n",
       " ('광남일보', 0),\n",
       " ('광주일보', 0),\n",
       " ('국제신문', 0),\n",
       " ('내일신문', 0),\n",
       " ('뉴제주일보', 0),\n",
       " ('대구일보', 0),\n",
       " ('대전일보', 0),\n",
       " ('데일리스포츠한국', 0),\n",
       " ('디지털타임즈', 0),\n",
       " ('매일신문', 0),\n",
       " ('무등일보', 0),\n",
       " ('부산일보', 0),\n",
       " ('국민일보', 0),\n",
       " ('동아일보', 0),\n",
       " ('매일경제', 0),\n",
       " ('파이낸셜 뉴스', 0),\n",
       " ('머니투데이', 0),\n",
       " ('경남일보', 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "total = 0\n",
    "for k, v in media2site.items():\n",
    "    tmp = result[result['매체명']==k]['link1'].tolist()\n",
    "    links.append((k, len(tmp)))\n",
    "    total += len(tmp)\n",
    "    tmp = result[result['매체명']==k]['link2'].tolist()\n",
    "    total += len(tmp)\n",
    "    tmp = result[result['매체명']==k]['link3'].tolist()\n",
    "    total += len(tmp)\n",
    "\n",
    "print(total)\n",
    "sorted(links, key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) 아주경제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='아주경제']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='아주경제']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='아주경제']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    result_title = [[],[],[]]\n",
    "    result_text = [[],[],[]]\n",
    "    result_date = [[],[],[]]\n",
    "    if media2site['아주경제'] in link1 and link1 != 'https://www.ajunews.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            title, date = driver.find_element('class name', 'view_header').text.split('\\n')\n",
    "            date = date[3:]\n",
    "            text = driver.find_element('class name', 'article_con').text\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[0].append(title)\n",
    "    result_text[0].append(text)\n",
    "    result_date[0].append(date)\n",
    "\n",
    "    if media2site['아주경제'] in link2 and link2 != 'https://www.ajunews.com/':\n",
    "        try:\n",
    "            driver.get(link2)\n",
    "            title, date = driver.find_element('class name', 'view_header').text.split('\\n')\n",
    "            date = date[3:]\n",
    "            text = driver.find_element('class name', 'article_con').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[1].append(title)\n",
    "    result_text[1].append(text)\n",
    "    result_date[1].append(date)\n",
    "\n",
    "    if media2site['아주경제'] in link3 and link3 != 'https://www.ajunews.com/':\n",
    "        try:\n",
    "            driver.get(link3)\n",
    "            title, date = driver.find_element('class name', 'view_header').text.split('\\n')\n",
    "            date = date[3:]\n",
    "            text = driver.find_element('class name', 'article_con').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[2].append(title)\n",
    "    result_text[2].append(text)\n",
    "    result_date[2].append(date)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) 일간스포츠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='일간스포츠']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='일간스포츠']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='일간스포츠']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "result_title = [[],[],[]]\n",
    "result_text = [[],[],[]]\n",
    "result_date = [[],[],[]]\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    if media2site['일간스포츠'] in link1 and link1 != 'https://isplus.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'title').text\n",
    "            date = driver.find_element('class name', 'time_bx').text[3:]\n",
    "            text = driver.find_element('id', 'article_body').text\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = ''\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[0].append(title)\n",
    "    result_text[0].append(text)\n",
    "    result_date[0].append(date)\n",
    "\n",
    "    if media2site['일간스포츠'] in link2 and link2 != 'https://isplus.com/':\n",
    "        try:\n",
    "            driver.get(link2)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'title').text\n",
    "            date = driver.find_element('class name', 'time_bx').text[3:]\n",
    "            text = driver.find_element('id', 'article_body').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[1].append(title)\n",
    "    result_text[1].append(text)\n",
    "    result_date[1].append(date)\n",
    "\n",
    "    if media2site['일간스포츠'] in link3 and link3 != 'https://isplus.com/':\n",
    "        try:\n",
    "            driver.get(link3)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'title').text\n",
    "            date = driver.find_element('class name', 'time_bx').text[3:]\n",
    "            text = driver.find_element('id', 'article_body').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = ''\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "        \n",
    "    result_title[2].append(title)\n",
    "    result_text[2].append(text)\n",
    "    result_date[2].append(date)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) 아시아경제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='아시아경제']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='아시아경제']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='아시아경제']['link3'].tolist()\n",
    "\n",
    "result_title = [[],[],[]]\n",
    "result_text = [[],[],[]]\n",
    "result_date = [[],[],[]]\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    if media2site['아시아경제'] in link1 and link1 != 'https://www.sedaily.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'area_title').find_element('tag name', 'h1').text\n",
    "            date = driver.find_element('class name', 'date_box').find_element('tag name', 'p').text[2:]\n",
    "            text = driver.find_element('id', 'txt_area').text\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[0].append(title)\n",
    "    result_text[0].append(text)\n",
    "    result_date[0].append(date)\n",
    "\n",
    "    if media2site['아시아경제'] in link2 and link2 != 'https://www.sedaily.com/':\n",
    "        try:\n",
    "            driver.get(link2)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'area_title').find_element('tag name', 'h1').text\n",
    "            date = driver.find_element('class name', 'date_box').find_element('tag name', 'p').text[2:]\n",
    "            text = driver.find_element('id', 'txt_area').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[1].append(title)\n",
    "    result_text[1].append(text)\n",
    "    result_date[1].append(date)\n",
    "\n",
    "    if media2site['아시아경제'] in link3 and link3 != 'https://www.sedaily.com/':\n",
    "        try:\n",
    "            driver.get(link3)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'area_title').find_element('tag name', 'h1').text\n",
    "            date = driver.find_element('class name', 'date_box').find_element('tag name', 'p').text[2:]\n",
    "            text = driver.find_element('id', 'txt_area').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "        \n",
    "    result_title[2].append(title)\n",
    "    result_text[2].append(text)\n",
    "    result_date[2].append(date)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) 중앙일보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='중앙일보']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='중앙일보']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='중앙일보']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "result_text = [[],[],[]]\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    if media2site['중앙일보'] in link1 and link1 != 'https://www.joongang.co.kr/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            driver.implicitly_wait(10)\n",
    "            text = driver.find_element('id', 'article_body').text\n",
    "\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            text = ''\n",
    "    else:\n",
    "        text = ''\n",
    "        driver.refresh()\n",
    "\n",
    "    result_text[0].append(text)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) 파이낸셜뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='파이낸셜뉴스']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='파이낸셜뉴스']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='파이낸셜뉴스']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "result_title = [[],[],[]]\n",
    "result_text = [[],[],[]]\n",
    "result_date = [[],[],[]]\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    if media2site['파이낸셜뉴스'] in link1 and link1 != 'http://fnnews.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            driver.implicitly_wait(10)\n",
    "            title = driver.find_element('class name', 'tit_view').text\n",
    "            date = driver.find_element('class name', 'byline').text[9:20]\n",
    "            text = driver.find_element('id', 'article_content').text\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = ''\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[0].append(title)\n",
    "    result_text[0].append(text)\n",
    "    result_date[0].append(date)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fnnews = result[result['매체명']=='파이낸셜뉴스'].copy()\n",
    "\n",
    "result_fnnews['title1'] = result_title[0]\n",
    "result_fnnews['text1'] = result_text[0]\n",
    "result_fnnews['date1'] = result_date[0]\n",
    "\n",
    "# csv파일로 저장\n",
    "# 1) result파일 6개로 나눠서 크롤링했다면, 따로 저장 후 나중에 합치시면 됩니다.\n",
    "result_fnnews.to_csv('result_fnnews1.csv')\n",
    "# result_fnnews.to_csv('result_fnnews2.csv')\n",
    "# result_fnnews.to_csv('result_fnnews3.csv')\n",
    "# result_fnnews.to_csv('result_fnnews4.csv')\n",
    "# result_fnnews.to_csv('result_fnnews5.csv')\n",
    "# result_fnnews.to_csv('result_fnnews6.csv')\n",
    "\n",
    "# 2) result파일 합쳐서 크롤링했다면\n",
    "result_fnnews.to_csv('result_fnnews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) 한국경제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='한국경제']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='한국경제']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='한국경제']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    result_title = [[],[],[]]\n",
    "    result_text = [[],[],[]]\n",
    "    result_date = [[],[],[]]\n",
    "    if media2site['한국경제'] in link1 and link1 != 'https://www.hankyung.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            title = driver.find_element('class name', 'article-contents').find_element('class name', 'headline').text\n",
    "            date = driver.find_element('class name', 'txt-date').text[:10]\n",
    "            text = driver.find_element('class name', 'article-body').text\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[0].append(title)\n",
    "    result_text[0].append(text)\n",
    "    result_date[0].append(date)\n",
    "\n",
    "    if media2site['한국경제'] in link2 and link2 != 'https://www.hankyung.com/':\n",
    "        try:\n",
    "            driver.get(link2)\n",
    "            title = driver.find_element('class name', 'article-contents').find_element('class name', 'headline').text\n",
    "            date = driver.find_element('class name', 'txt-date').text[:10]\n",
    "            text = driver.find_element('class name', 'article-body').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[1].append(title)\n",
    "    result_text[1].append(text)\n",
    "    result_date[1].append(date)\n",
    "\n",
    "    if media2site['한국경제'] in link3 and link3 != 'https://www.hankyung.com/':\n",
    "        try:\n",
    "            driver.get(link3)\n",
    "            title = driver.find_element('class name', 'article-contents').find_element('class name', 'headline').text\n",
    "            date = driver.find_element('class name', 'txt-date').text[:10]\n",
    "            text = driver.find_element('class name', 'article-body').text\n",
    "        except Exception as error:\n",
    "            # print(error)\n",
    "            title = ''\n",
    "            text = ''\n",
    "            date = '' \n",
    "            driver.refresh()\n",
    "    else:\n",
    "        title = ''\n",
    "        text = ''\n",
    "        date = ''\n",
    "    result_title[2].append(title)\n",
    "    result_text[2].append(text)\n",
    "    result_date[2].append(date)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) 조선일보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\seenw\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')\n",
    "\n",
    "newslinks1 = result[result['매체명']=='조선일보']['link1'].tolist()\n",
    "newslinks2 = result[result['매체명']=='조선일보']['link2'].tolist()\n",
    "newslinks3 = result[result['매체명']=='조선일보']['link3'].tolist()\n",
    "print(len(newslinks1))\n",
    "\n",
    "for link1, link2, link3 in zip(newslinks1, newslinks2, newslinks3):\n",
    "    result_title = [[],[],[]]\n",
    "    result_text = [[],[],[]]\n",
    "    result_date = [[],[],[]]\n",
    "    \n",
    "    if 'biz.chosun.com' in link1:\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            # title = driver.find_element('class name', 'article-header__headline-container').text\n",
    "            # date = driver.find_element('class name', 'article-time').text[3:-6]\n",
    "            text = driver.find_element('class name', 'article-body').text\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            # title = ''\n",
    "            # date = '' \n",
    "            text = ''\n",
    "    \n",
    "    elif 'health.chosun.com' in link1:\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            # title = driver.find_element('id', 'news_title_text_id')\n",
    "            # date = driver.find_element\n",
    "            text = driver.find_element('class name', 'par').text\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            # title = ''\n",
    "            # date = '' \n",
    "            text = ''\n",
    "\n",
    "    elif 'boutique.chosun.com' in link1:\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            text = driver.find_element('class name', 'par').text\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            # title = ''\n",
    "            # date = '' \n",
    "            text = ''\n",
    "\n",
    "    elif 'srchdb1.chosun.com' in link1:\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            text = driver.find_element('id', 'article').text[8:]\n",
    "\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            # title = ''\n",
    "            # date = '' \n",
    "            text = ''\n",
    "\n",
    "    elif 'chosun.com' in link1 and link1 != 'https://www.chosun.com/':\n",
    "        try:\n",
    "            driver.get(link1)\n",
    "            article = driver.find_element('class name', 'article-body').find_elements('tag name', 'p')\n",
    "            text = ''\n",
    "            for a in article:\n",
    "                text += a.text\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            text = ''\n",
    "\n",
    "    else:\n",
    "        # title = ''\n",
    "        # date = ''\n",
    "        text = ''\n",
    "        driver.refresh()\n",
    "\n",
    "    # result_title[0].append(title)\n",
    "    # result_date[0].append(date)\n",
    "    result_text[0].append(text)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-dialogue-summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
